{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template -- ECG data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E528Yh1i4RWg"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to use from Colab environment\n",
        "!git clone https://github.com/jveenland/tm10007_ml.git\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
        "from scipy.stats import uniform, loguniform\n",
        "\n",
        "# Extract dataset\n",
        "with zipfile.ZipFile('/content/tm10007_ml/ecg/ecg_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "data_path = os.path.join(os.getcwd(), 'ecg_data.csv')\n",
        "data = pd.read_csv(data_path, index_col=0)\n",
        "\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of features: {len(data.columns) - 1}')  # Excluding label column\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :-1].values  # All columns except the last one\n",
        "y = data.iloc[:, -1].values   # Last column as labels\n",
        "\n",
        "# Scale the features\n",
        "scaler = RobustScaler(quantile_range=(30, 70))\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define outer and inner loop random seeds\n",
        "outer = range(0, 5)  # Outer loop (train-test variations)\n",
        "inner = range(0, 5)  # Inner loop (hyperparameter tuning)\n",
        "\n",
        "best_params_list = {}  # Stores best params per (outer, inner) iteration\n",
        "hyperparam_accuracies = {}  # Stores accuracies per hyperparameter set\n",
        "\n",
        "# Generate a fixed set of random hyperparameter sets (same for all outer loops)\n",
        "fixed_hyperparam_sets = []\n",
        "for _ in range(10):  # Generate 10 random hyperparameter sets\n",
        "    param_set = {\n",
        "        'C': loguniform(0.01, 1000).rvs(),\n",
        "        'gamma': loguniform(0.0001, 100).rvs(),\n",
        "        'class_weight': random.choice(['balanced', None]),\n",
        "        'shrinking': random.choice([True, False]),\n",
        "        'tol': uniform(1e-5, 1e-2).rvs()\n",
        "    }\n",
        "    fixed_hyperparam_sets.append(param_set)\n",
        "    hyperparam_accuracies[str(param_set)] = []  # Initialize list for accuracy tracking\n",
        "\n",
        "# Outer loop for train-test split variations\n",
        "for outer_rand in tqdm(outer, desc='Outer Loop'):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.2, random_state=outer_rand, stratify=y  # Maintain class proportions\n",
        "    )\n",
        "\n",
        "    # Apply PCA to reduce dimensionality (fit only on training data)\n",
        "    pca = PCA(n_components=0.99)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "    X_test_pca = pca.transform(X_test)\n",
        "\n",
        "    # Print PCA variance explained\n",
        "    print(f\"Explained Variance by PCA Components: {pca.explained_variance_ratio_.sum()}\")\n",
        "\n",
        "    # Inner loop for hyperparameter tuning\n",
        "    for inner_rand, param_set in tqdm(enumerate(fixed_hyperparam_sets), desc='Inner Loop', leave=True):\n",
        "        X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
        "            X_train_pca, y_train, test_size=0.15, random_state=inner_rand, stratify=y_train  # Maintain class proportions\n",
        "        )\n",
        "\n",
        "        # Initialize SVM model with RBF kernel\n",
        "        svm = SVC(kernel='rbf', **param_set, probability=True)  # Enable probability for AUC calculation\n",
        "\n",
        "        # Train and evaluate model\n",
        "        start_time = time.time()\n",
        "        svm.fit(X_train_train, y_train_train)\n",
        "        elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "\n",
        "        # Best model evaluation\n",
        "        y_pred = svm.predict(X_test_pca)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1=f1_score(y_test,y_pred)\n",
        "\n",
        "        # Compute confusion matrix for sensitivity and specificity\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()  # True negatives, False positives, False negatives, True positives\n",
        "        sensitivity = tp / (tp + fn)\n",
        "        specificity = tn / (tn + fp)\n",
        "\n",
        "        # Compute AUC\n",
        "        auc = roc_auc_score(y_test, svm.predict_proba(X_test_pca)[:, 1])\n",
        "\n",
        "        # Store results\n",
        "        param_key = str(param_set)  # Convert to string for dict key\n",
        "        hyperparam_accuracies[param_key].append(accuracy)  # Store accuracy\n",
        "\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"] = param_set.copy()\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['accuracy'] = accuracy\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['sensitivity'] = sensitivity\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['specificity'] = specificity\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['auc'] = auc\n",
        "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['f1-score'] = f1\n",
        "\n",
        "        print(f\"\\nOuter {outer_rand}, Inner {inner_rand} -> Hyperparameters: {param_set}\")\n",
        "        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "        print(f\"Specificity: {specificity:.4f}\")\n",
        "        print(f\"AUC: {auc:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Select the best classifier based on the F1 score\n",
        "best_f1_score = -1\n",
        "best_classifier = None\n",
        "best_metrics = {}\n",
        "\n",
        "for key, val in best_params_list.items():\n",
        "    f1 = val['f1-score']\n",
        "\n",
        "    # Update if current F1 score is higher\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_classifier = key\n",
        "        best_metrics = val  # Store the metrics of the best classifier\n",
        "\n",
        "# Print the best classifier based on F1 score\n",
        "print(f\"\\nüèÜ Best Classifier Based on F1 Score: {best_classifier}\")\n",
        "print(f\"F1 Score: {best_f1_score:.4f}\")\n",
        "\n",
        "# Print the detailed metrics of the best classifier\n",
        "print(f\"\\nDetailed Metrics of the Best Classifier:\")\n",
        "print(f\"Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"Sensitivity: {best_metrics['sensitivity']:.4f}\")\n",
        "print(f\"Specificity: {best_metrics['specificity']:.4f}\")\n",
        "print(f\"AUC: {best_metrics['auc']:.4f}\")\n",
        "print(f\"F1 Score: {best_metrics['f1-score']:.4f}\")\n"
      ],
      "metadata": {
        "id": "xai9DpmN5agD",
        "outputId": "1a0e8d99-e086-486b-a99f-62d06f67b82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tm10007_ml' already exists and is not an empty directory.\n",
            "The number of samples: 827\n",
            "The number of features: 9000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}