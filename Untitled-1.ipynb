{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 827\n",
      "The number of columns: 9001\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "\n",
    "# Import necessary libraries\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn import datasets as ds, metrics, model_selection, feature_selection, preprocessing, neighbors, svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def colorplot(clf, ax, x, y, h=100, precomputer=None):\n",
    "    '''\n",
    "    Overlay the decision areas as colors in an axes.\n",
    "\n",
    "    Input:\n",
    "        clf: trained classifier\n",
    "        ax: axis to overlay color mesh on\n",
    "        x: feature on x-axis\n",
    "        y: feature on y-axis\n",
    "        h(optional): steps in the mesh\n",
    "    '''\n",
    "    # Create a meshgrid the size of the axis\n",
    "    xstep = (x.max() - x.min()) / 20.0\n",
    "    ystep = (y.max() - y.min()) / 20.0\n",
    "    x_min, x_max = x.min() - xstep, x.max() + xstep\n",
    "    y_min, y_max = y.min() - ystep, y.max() + ystep\n",
    "    h = max((x_max - x_min, y_max - y_min)) / h\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    features = np.c_[xx.ravel(), yy.ravel()]\n",
    "    if precomputer is not None:\n",
    "        if type(precomputer) is RBFSampler:\n",
    "            features = precomputer.transform(features)\n",
    "        elif precomputer is rbf_kernel:\n",
    "            features = rbf_kernel(features, X)\n",
    "    \n",
    "    # Compute decision boundary\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(features)\n",
    "    else:\n",
    "        Z = clf.predict_proba(features)\n",
    "    if len(Z.shape) > 1:\n",
    "        Z = Z[:, 1]\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    cm = plt.cm.RdBu_r\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    \n",
    "    del xx, yy, x_min, x_max, y_min, y_max, Z, cm\n",
    "\n",
    "# Extract ECG data\n",
    "zip_path = 'ecg_data.zip'\n",
    "extract_path = '.'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Load dataset\n",
    "data_path = os.path.join(extract_path, 'ecg_data.csv')\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "# Print dataset info\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and labels\n",
    "x = data.iloc[:, 0:-1].values  # Selecting all columns except last\n",
    "y = data.iloc[:, -1].values  # Selecting last column as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n"
     ]
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "forest.fit(x, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(x.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Select only the top 300 features\n",
    "valuable_x = x[:, indices[:100]]\n",
    "# valuable_x = pd.DataFrame(valuable_x, columns=[f'feature_{i}' for i in indices[:300]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Testing: 100%|██████████| 20/20 [03:22<00:00, 10.14s/split]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "Train Accuracy: 0.9152542372881356\n",
      "Train AUC: 0.9973408541498792\n",
      "Train F1: 0.6846846846846847\n",
      "Train Precision: 1.0\n",
      "Train Recall: 0.5205479452054794\n",
      "Test Accuracy: 0.8695652173913043\n",
      "Test AUC: 0.8731370264733057\n",
      "Test F1: 0.4489795918367347\n",
      "Test Precision: 0.88\n",
      "Test Recall: 0.3013698630136986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Repeat the experiment 20 times\n",
    "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Adjusted hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],  # Reduced n_estimators\n",
    "    'max_depth': [5, 10, 15],  # Reduced max_depth range\n",
    "    'min_samples_split': [2, 5, 10, 20],  # Keep min_samples_split moderate\n",
    "    'min_samples_leaf': [5, 10, 20],  # Increased min_samples_leaf\n",
    "    'max_features': ['sqrt', 'log2']  # Removed None to focus on these options\n",
    "}\n",
    "\n",
    "for train_index, test_index in tqdm(sss.split(valuable_x, y), total=20, desc=\"Training and Testing\", unit=\"split\"):\n",
    "    split_X_train, split_y_train = valuable_x[train_index], y[train_index]\n",
    "    split_X_test, split_y_test = valuable_x[test_index], y[test_index]\n",
    "\n",
    "    # Perform RandomizedSearchCV to tune hyperparameters\n",
    "    base_clf = RandomForestClassifier()\n",
    "    clf = RandomizedSearchCV(base_clf, param_dist, n_iter=30, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "    clf.fit(split_X_train, split_y_train)\n",
    "    best_clf = clf.best_estimator_\n",
    "\n",
    "    # Loop through all the possible number of features (1 to max features)\n",
    "    for num_features in range(1, split_X_train.shape[1] + 1):  # Looping over all feature counts\n",
    "        # Select the top k features dynamically\n",
    "        feature_selector = SelectKBest(f_classif, k=num_features)\n",
    "        split_X_train_selected = feature_selector.fit_transform(split_X_train, split_y_train)\n",
    "        split_X_test_selected = feature_selector.transform(split_X_test)\n",
    "\n",
    "        # Train the classifier on the selected features\n",
    "        best_clf.fit(split_X_train_selected, split_y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = best_clf.predict(split_X_train_selected)\n",
    "        y_pred_test = best_clf.predict(split_X_test_selected)\n",
    "\n",
    "        # Compute scores for training set\n",
    "        y_score_train = best_clf.predict_proba(split_X_train_selected)[:, 1] if hasattr(best_clf, 'predict_proba') else y_pred_train\n",
    "        auc_train = metrics.roc_auc_score(split_y_train, y_score_train)\n",
    "        accuracy_train = metrics.accuracy_score(split_y_train, y_pred_train)\n",
    "        F1_train = metrics.f1_score(split_y_train, y_pred_train)\n",
    "        precision_train = metrics.precision_score(split_y_train, y_pred_train)\n",
    "        recall_train = metrics.recall_score(split_y_train, y_pred_train)\n",
    "        train_scores.append((accuracy_train, auc_train, F1_train, precision_train, recall_train))\n",
    "\n",
    "        # Compute scores for test set\n",
    "        y_score_test = best_clf.predict_proba(split_X_test_selected)[:, 1] if hasattr(best_clf, 'predict_proba') else y_pred_test\n",
    "        auc_test = metrics.roc_auc_score(split_y_test, y_score_test)\n",
    "        accuracy_test = metrics.accuracy_score(split_y_test, y_pred_test)\n",
    "        F1_test = metrics.f1_score(split_y_test, y_pred_test)\n",
    "        precision_test = metrics.precision_score(split_y_test, y_pred_test)\n",
    "        recall_test = metrics.recall_score(split_y_test, y_pred_test)\n",
    "        test_scores.append((accuracy_test, auc_test, F1_test, precision_test, recall_test))\n",
    "\n",
    "# Print evaluation metrics for the last split\n",
    "print(f'Best Parameters: {clf.best_params_}')\n",
    "print(f'Train Accuracy: {accuracy_train}')\n",
    "print(f'Train AUC: {auc_train}')\n",
    "print(f'Train F1: {F1_train}')\n",
    "print(f'Train Precision: {precision_train}')\n",
    "print(f'Train Recall: {recall_train}')\n",
    "print(f'Test Accuracy: {accuracy_test}')\n",
    "print(f'Test AUC: {auc_test}')\n",
    "print(f'Test F1: {F1_test}')\n",
    "print(f'Test Precision: {precision_test}')\n",
    "print(f'Test Recall: {recall_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "x = data.iloc[:, 0:-1].values  # Selecting all columns except the first and last\n",
    "y = data.iloc[:, -1].values  # Selecting last column as labels\n",
    "\n",
    "scaler = RobustScaler(quantile_range=(25,75))\n",
    "scaled_valuable_x = scaler.fit_transform(valuable_x)\n",
    "\n",
    "# Manually specify column names (assuming you know the original column names)\n",
    "# scaled_valuable_x = pd.DataFrame(scaled_data, columns=data.columns[0:-1])  # Use the same column names from data\n",
    "\n",
    "print(scaled_valuable_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Testing: 100%|██████████| 20/20 [00:05<00:00,  3.43split/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm._classes.SVC'>\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'degree': 2, 'C': 10}\n",
      "Train Acc: 0.9539951573849879\n",
      "Train AUC: 0.9649073327961322\n",
      "Train F1: 0.8503937007874016\n",
      "Train Precision: 1.0\n",
      "Train Recall: 0.7397260273972602\n",
      "Test Acc: 0.8647342995169082\n",
      "Test AUC: 0.8412806813160327\n",
      "Test F1: 0.5254237288135594\n",
      "Test Precision: 0.6888888888888889\n",
      "Test Recall: 0.4246575342465753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "# Repeat the experiment 20 times\n",
    "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Adjusted hyperparameter grid for SVM\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'],  # Different kernels for SVM\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel (if using 'poly')\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf' and 'poly'\n",
    "}\n",
    "\n",
    "for train_index, test_index in tqdm(sss.split(scaled_valuable_x, y), total=20, desc=\"Training and Testing\", unit=\"split\"):\n",
    "    split_X_train, split_y_train = scaled_valuable_x[train_index], y[train_index]\n",
    "    split_X_test, split_y_test = scaled_valuable_x[test_index], y[test_index]\n",
    "\n",
    "    # Hyperparameter tuning with RandomizedSearchCV for SVM\n",
    "    base_clf = SVC()\n",
    "    clf = RandomizedSearchCV(base_clf, param_dist, n_iter=30, cv=3, n_jobs=-1, scoring='balanced_accuracy')  # Changed to balanced_accuracy\n",
    "    clf.fit(split_X_train, split_y_train)\n",
    "    best_clf = clf.best_estimator_\n",
    "\n",
    "    y_pred_train = best_clf.predict(split_X_train)\n",
    "    y_pred_test = best_clf.predict(split_X_test)\n",
    "\n",
    "    # Compute scores for training set\n",
    "    y_score_train = best_clf.decision_function(split_X_train) if hasattr(best_clf, 'decision_function') else y_pred_train\n",
    "    auc_train = metrics.roc_auc_score(split_y_train, y_score_train)\n",
    "    accuracy_train = metrics.accuracy_score(split_y_train, y_pred_train)\n",
    "    F1_train = metrics.f1_score(split_y_train, y_pred_train)\n",
    "    precision_train = metrics.precision_score(split_y_train, y_pred_train)\n",
    "    recall_train = metrics.recall_score(split_y_train, y_pred_train)\n",
    "    train_scores.append((accuracy_train, auc_train, F1_train, precision_train, recall_train))\n",
    "\n",
    "    # Compute scores for test set\n",
    "    y_score_test = best_clf.decision_function(split_X_test) if hasattr(best_clf, 'decision_function') else y_pred_test\n",
    "    auc_test = metrics.roc_auc_score(split_y_test, y_score_test)\n",
    "    accuracy_test = metrics.accuracy_score(split_y_test, y_pred_test)\n",
    "    F1_test = metrics.f1_score(split_y_test, y_pred_test)\n",
    "    precision_test = metrics.precision_score(split_y_test, y_pred_test)\n",
    "    recall_test = metrics.recall_score(split_y_test, y_pred_test)\n",
    "    test_scores.append((accuracy_test, auc_test, F1_test, precision_test, recall_test))\n",
    "\n",
    "# Print evaluation metrics for the last split\n",
    "print(type(best_clf))\n",
    "print('Best Parameters:', clf.best_params_)\n",
    "print('Train Acc:', accuracy_train)\n",
    "print('Train AUC:', auc_train)\n",
    "print('Train F1:', F1_train)\n",
    "print('Train Precision:', precision_train)\n",
    "print('Train Recall:', recall_train)\n",
    "print('Test Acc:', accuracy_test)\n",
    "print('Test AUC:', auc_test)\n",
    "print('Test F1:', F1_test)\n",
    "print('Test Precision:', precision_test)\n",
    "print('Test Recall:', recall_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Testing: 100%|██████████| 20/20 [00:35<00:00,  1.80s/split]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.1, 'lambda': 1.0, 'gamma': 0.5, 'colsample_bytree': 0.7, 'alpha': 1.0}\n",
      "Train Accuracy: 0.9927360774818402\n",
      "Train AUC: 1.0\n",
      "Train F1: 0.9790209790209791\n",
      "Train Precision: 1.0\n",
      "Train Recall: 0.958904109589041\n",
      "Test Accuracy: 0.8695652173913043\n",
      "Test AUC: 0.8332061222030289\n",
      "Test F1: 0.5263157894736842\n",
      "Test Precision: 0.7317073170731707\n",
      "Test Recall: 0.410958904109589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## XGB Classifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "# Repeat the experiment 20 times\n",
    "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Adjusted hyperparameter grid with stronger regularization\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],  # Lowered n_estimators\n",
    "    'max_depth': [2, 3, 4],  # Keeping depth shallow\n",
    "    'learning_rate': [0.05, 0.1, 0.2],  # Slightly varying learning rate\n",
    "    'subsample': [0.7, 0.8, 0.9],  # Reduce subsampling slightly\n",
    "    'colsample_bytree': [0.7, 0.8],  # Feature subsampling\n",
    "    'gamma': [0.1, 0.5, 1.0],  # Higher regularization\n",
    "    'lambda': [0.1, 0.5, 1.0],  # L2 regularization\n",
    "    'alpha': [0.1, 0.5, 1.0]  # L1 regularization\n",
    "}\n",
    "\n",
    "for train_index, test_index in tqdm(sss.split(valuable_x, y), total=20, desc=\"Training and Testing\", unit=\"split\"):\n",
    "    split_X_train, split_y_train = valuable_x[train_index], y[train_index]\n",
    "    split_X_test, split_y_test = valuable_x[test_index], y[test_index]\n",
    "\n",
    "    # Perform RandomizedSearchCV to tune hyperparameters\n",
    "    base_clf = XGBClassifier(use_label_encoder=False, verbosity=0)\n",
    "    clf = RandomizedSearchCV(base_clf, param_dist, n_iter=30, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "    clf.fit(split_X_train, split_y_train)\n",
    "    best_clf = clf.best_estimator_\n",
    "\n",
    "    # Instead of looping over all features, test only meaningful fractions\n",
    "    feature_fractions = [0.25, 0.5, 0.75]  # Use only 25%, 50%, 75% of features\n",
    "    for frac in feature_fractions:\n",
    "        num_features = int(split_X_train.shape[1] * frac)\n",
    "        num_features = max(1, num_features)  # Ensure at least 1 feature\n",
    "\n",
    "        feature_selector = SelectKBest(f_classif, k=num_features)\n",
    "        split_X_train_selected = feature_selector.fit_transform(split_X_train, split_y_train)\n",
    "        split_X_test_selected = feature_selector.transform(split_X_test)\n",
    "\n",
    "        # Train the classifier on the selected features\n",
    "        best_clf.fit(split_X_train_selected, split_y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = best_clf.predict(split_X_train_selected)\n",
    "        y_pred_test = best_clf.predict(split_X_test_selected)\n",
    "\n",
    "        # Compute scores for training set\n",
    "        y_score_train = best_clf.predict_proba(split_X_train_selected)[:, 1] if hasattr(best_clf, 'predict_proba') else y_pred_train\n",
    "        auc_train = metrics.roc_auc_score(split_y_train, y_score_train)\n",
    "        accuracy_train = metrics.accuracy_score(split_y_train, y_pred_train)\n",
    "        F1_train = metrics.f1_score(split_y_train, y_pred_train)\n",
    "        precision_train = metrics.precision_score(split_y_train, y_pred_train)\n",
    "        recall_train = metrics.recall_score(split_y_train, y_pred_train)\n",
    "        train_scores.append((accuracy_train, auc_train, F1_train, precision_train, recall_train))\n",
    "\n",
    "        # Compute scores for test set\n",
    "        y_score_test = best_clf.predict_proba(split_X_test_selected)[:, 1] if hasattr(best_clf, 'predict_proba') else y_pred_test\n",
    "        auc_test = metrics.roc_auc_score(split_y_test, y_score_test)\n",
    "        accuracy_test = metrics.accuracy_score(split_y_test, y_pred_test)\n",
    "        F1_test = metrics.f1_score(split_y_test, y_pred_test)\n",
    "        precision_test = metrics.precision_score(split_y_test, y_pred_test)\n",
    "        recall_test = metrics.recall_score(split_y_test, y_pred_test)\n",
    "        test_scores.append((accuracy_test, auc_test, F1_test, precision_test, recall_test))\n",
    "\n",
    "# Print evaluation metrics for the last split\n",
    "print(f'Best Parameters: {clf.best_params_}')\n",
    "print(f'Train Accuracy: {accuracy_train}')\n",
    "print(f'Train AUC: {auc_train}')\n",
    "print(f'Train F1: {F1_train}')\n",
    "print(f'Train Precision: {precision_train}')\n",
    "print(f'Train Recall: {recall_train}')\n",
    "print(f'Test Accuracy: {accuracy_test}')\n",
    "print(f'Test AUC: {auc_test}')\n",
    "print(f'Test F1: {F1_test}')\n",
    "print(f'Test Precision: {precision_test}')\n",
    "print(f'Test Recall: {recall_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training and Testing: 100%|██████████| 20/20 [00:01<00:00, 10.42split/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9903147699757869\n",
      "Train AUC: 0.9997179693795326\n",
      "Train F1: 0.971830985915493\n",
      "Train Precision: 1.0\n",
      "Train Recall: 0.9452054794520548\n",
      "Test Accuracy: 0.857487922705314\n",
      "Test AUC: 0.8309163218575503\n",
      "Test F1: 0.48695652173913045\n",
      "Test Precision: 0.6666666666666666\n",
      "Test Recall: 0.3835616438356164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## XGBClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "# Fixed best parameters\n",
    "best_params = {\n",
    "    'subsample': 0.9,\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'lambda': 1.0,\n",
    "    'gamma': 0.5,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'alpha': 1.0\n",
    "}\n",
    "\n",
    "# Repeat the experiment 20 times\n",
    "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=0)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for train_index, test_index in tqdm(sss.split(valuable_x, y), total=20, desc=\"Training and Testing\", unit=\"split\"):\n",
    "    split_X_train, split_y_train = valuable_x[train_index], y[train_index]\n",
    "    split_X_test, split_y_test = valuable_x[test_index], y[test_index]\n",
    "\n",
    "    # Initialize classifier with fixed best parameters\n",
    "    best_clf = XGBClassifier(**best_params, use_label_encoder=False, verbosity=0)\n",
    "    \n",
    "    # Feature selection (using 50% of features as an example)\n",
    "    num_features = int(split_X_train.shape[1] * 0.5)\n",
    "    num_features = max(1, num_features)  # Ensure at least 1 feature\n",
    "\n",
    "    feature_selector = SelectKBest(f_classif, k=num_features)\n",
    "    split_X_train_selected = feature_selector.fit_transform(split_X_train, split_y_train)\n",
    "    split_X_test_selected = feature_selector.transform(split_X_test)\n",
    "\n",
    "    # Train classifier on selected features\n",
    "    best_clf.fit(split_X_train_selected, split_y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = best_clf.predict(split_X_train_selected)\n",
    "    y_pred_test = best_clf.predict(split_X_test_selected)\n",
    "\n",
    "    # Compute scores for training set\n",
    "    y_score_train = best_clf.predict_proba(split_X_train_selected)[:, 1]\n",
    "    auc_train = metrics.roc_auc_score(split_y_train, y_score_train)\n",
    "    accuracy_train = metrics.accuracy_score(split_y_train, y_pred_train)\n",
    "    F1_train = metrics.f1_score(split_y_train, y_pred_train)\n",
    "    precision_train = metrics.precision_score(split_y_train, y_pred_train)\n",
    "    recall_train = metrics.recall_score(split_y_train, y_pred_train)\n",
    "    train_scores.append((accuracy_train, auc_train, F1_train, precision_train, recall_train))\n",
    "\n",
    "    # Compute scores for test set\n",
    "    y_score_test = best_clf.predict_proba(split_X_test_selected)[:, 1]\n",
    "    auc_test = metrics.roc_auc_score(split_y_test, y_score_test)\n",
    "    accuracy_test = metrics.accuracy_score(split_y_test, y_pred_test)\n",
    "    F1_test = metrics.f1_score(split_y_test, y_pred_test)\n",
    "    precision_test = metrics.precision_score(split_y_test, y_pred_test)\n",
    "    recall_test = metrics.recall_score(split_y_test, y_pred_test)\n",
    "    test_scores.append((accuracy_test, auc_test, F1_test, precision_test, recall_test))\n",
    "\n",
    "# Print evaluation metrics for the last split\n",
    "print(f'Train Accuracy: {accuracy_train}')\n",
    "print(f'Train AUC: {auc_train}')\n",
    "print(f'Train F1: {F1_train}')\n",
    "print(f'Train Precision: {precision_train}')\n",
    "print(f'Train Recall: {recall_train}')\n",
    "print(f'Test Accuracy: {accuracy_test}')\n",
    "print(f'Test AUC: {auc_test}')\n",
    "print(f'Test F1: {F1_test}')\n",
    "print(f'Test Precision: {precision_test}')\n",
    "print(f'Test Recall: {recall_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 100)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
