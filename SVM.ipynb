{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d3544e0",
      "metadata": {
        "id": "1d3544e0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, roc_auc_score, accuracy_score,\n",
        "    f1_score, precision_recall_curve, auc as pr_auc, make_scorer\n",
        ")\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "\n",
        "\n",
        "# Load data\n",
        "data_path = os.path.join(os.getcwd(), 'ecg_data.csv')\n",
        "data = pd.read_csv(data_path, index_col=0)\n",
        "\n",
        "x = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "outer = range(10)\n",
        "best_params_dict = {}\n",
        "best_model_dict = {}\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "auc_list = []\n",
        "\n",
        "for outer_rand in tqdm(outer, desc='Outer Loop'):\n",
        "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = train_test_split(\n",
        "        x, y, test_size=0.2, stratify=y, shuffle=True, random_state=outer_rand\n",
        "    )\n",
        "\n",
        "    # Apply MinMaxScaler and PCA separately to the data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_train_outer = scaler.fit_transform(X_train_outer)\n",
        "    X_test_outer = scaler.transform(X_test_outer)\n",
        "\n",
        "    pca = PCA(n_components=0.99, random_state=42)\n",
        "    X_train_outer = pca.fit_transform(X_train_outer)\n",
        "    X_test_outer = pca.transform(X_test_outer)\n",
        "\n",
        "    # Define pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('svc', SVC(kernel='rbf', probability=True))\n",
        "    ])\n",
        "\n",
        "    # Hyperparameter space for RandomizedSearchCV\n",
        "    param_grid_svc = {\n",
        "        'svc__C': loguniform(0.01, 1000),\n",
        "        'svc__gamma': loguniform(0.0001, 100),\n",
        "        'svc__class_weight': ['balanced', None],\n",
        "        'svc__shrinking': [True, False],\n",
        "        'svc__tol': uniform(1e-5, 1e-2)\n",
        "    }\n",
        "\n",
        "    cv_inner = StratifiedKFold(n_splits=7, shuffle=True, random_state=7)\n",
        "\n",
        "    def pr_auc_score(y_true, y_pred_proba):\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "        return pr_auc(recall, precision)\n",
        "\n",
        "    pr_auc_scorer = make_scorer(pr_auc_score, needs_proba=True)\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_distributions=param_grid_svc,\n",
        "        scoring=pr_auc_scorer,\n",
        "        cv=cv_inner,\n",
        "        n_iter=100,\n",
        "        n_jobs=-1,\n",
        "        random_state=7\n",
        "    )\n",
        "\n",
        "    random_search.fit(X_train_outer, y_train_outer)\n",
        "\n",
        "    best_model = random_search.best_estimator_\n",
        "    best_params = random_search.best_params_\n",
        "\n",
        "    y_pred = best_model.predict(X_test_outer)\n",
        "    y_pred_proba = best_model.predict_proba(X_test_outer)[:, 1]\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test_outer, y_pred).ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    auc_score = roc_auc_score(y_test_outer, y_pred_proba)\n",
        "    f1 = f1_score(y_test_outer, y_pred)\n",
        "    accuracy = accuracy_score(y_test_outer, y_pred)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_test_outer, y_pred_proba)\n",
        "    pr_score = pr_auc(recall, precision)\n",
        "\n",
        "    best_params_dict[f\"Outer {outer_rand}\"] = {\n",
        "        **best_params,\n",
        "        'auc': auc_score,\n",
        "        'f1': f1,\n",
        "        'sensitivity': sensitivity,\n",
        "        'specificity': specificity,\n",
        "        'accuracy': accuracy,\n",
        "        'pr_auc': pr_score\n",
        "    }\n",
        "    best_model_dict[f\"Outer {outer_rand}\"] = best_model\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    auc_list.append(pr_score)\n",
        "\n",
        "    # Save best parameters\n",
        "    results_df = pd.DataFrame.from_dict(best_params_dict, orient='index')\n",
        "    results_csv_path = os.path.join(os.getcwd(), 'svm_best_hyperparameters_randomsearch.csv')\n",
        "    results_df.to_csv(results_csv_path)\n",
        "\n",
        "    # Save PR curve data\n",
        "    pr_data = {\n",
        "        \"precision_list\": precision_list,\n",
        "        \"recall_list\": recall_list,\n",
        "        \"auc_list\": auc_list\n",
        "    }\n",
        "    pr_data_path = os.path.join(os.getcwd(), 'svm_precision_recall_data_randomsearch.pkl')\n",
        "    with open(pr_data_path, 'wb') as f:\n",
        "        pickle.dump(pr_data, f)\n",
        "\n",
        "# Load PR curve data\n",
        "with open(pr_data_path, 'rb') as f:\n",
        "    pr_data = pickle.load(f)\n",
        "\n",
        "precision_list = pr_data[\"precision_list\"]\n",
        "recall_list = pr_data[\"recall_list\"]\n",
        "auc_list = pr_data[\"auc_list\"]\n",
        "\n",
        "mean_recall = np.linspace(0, 1, 100)\n",
        "interp_precisions = []\n",
        "\n",
        "for precision, recall in zip(precision_list, recall_list):\n",
        "    order = np.argsort(recall)\n",
        "    recall_sorted = recall[order]\n",
        "    precision_sorted = precision[order]\n",
        "    interp = np.interp(mean_recall, recall_sorted, precision_sorted, left=1.0, right=0.0)\n",
        "    interp_precisions.append(interp)\n",
        "\n",
        "mean_precision = np.mean(interp_precisions, axis=0)\n",
        "std_precision = np.std(interp_precisions, axis=0)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(mean_recall, mean_precision, label=f\"Mean PR Curve (AUC = {np.mean(auc_list):.2f})\", color='purple')\n",
        "plt.fill_between(mean_recall, mean_precision - std_precision, mean_precision + std_precision,\n",
        "                 alpha=0.2, color='violet', label=\"±1 Std. Dev.\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"SVM Precision-Recall Curve (Mean ± Std) - RandomSearchCV\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "\n",
        "plot_path = os.path.join(os.getcwd(), 'svm_pr_curve_randomsearch.png')\n",
        "plt.savefig(plot_path)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
