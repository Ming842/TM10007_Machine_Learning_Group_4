{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer Loop:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer 0, Inner 0 -> Best Hyperparameters: {'n_estimators': 191, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.7872822447725126, 'max_depth': 24, 'bootstrap': True, 'auc': 0.5344827586206896, 'f1': 0.12903225806451613, 'sensitivity': 0.06896551724137931, 'specificity': 1.0, 'accuracy': 0.8373493975903614}\n",
      "Test Set Accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data_path = r'E:\\OneDrive\\School\\Technical Medicine\\TM Jaar 1\\Machine learning\\TM10007_Machine_Learning_Group_4\\TM\\ecg_data.csv'\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "# Splitting features and labels\n",
    "x = data.iloc[:, :-1].values  # Selecting all columns except last\n",
    "y = data.iloc[:, -1].values  # Selecting last column as labels\n",
    "\n",
    "# Define outer and inner loop random seeds\n",
    "outer = range(0, 5)  # Outer loop\n",
    "inner = range(0, 5)  # Inner loop\n",
    "\n",
    "best_params_list = {}\n",
    "\n",
    "# Outer loop for train-test split variations\n",
    "for outer_rand in tqdm(outer, desc='Outer Loop'):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, stratify=y, shuffle=True)\n",
    "        \n",
    "    \n",
    "\n",
    "    # Inner loop for hyperparameter tuning\n",
    "    for inner_rand in tqdm(inner, desc='Inner Loop', leave=True):\n",
    "        X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.15, stratify=y_train, shuffle=True)\n",
    "        \n",
    "        # Define the randomized parameter grid\n",
    "        param_grid_rf = {\n",
    "            'n_estimators': [random.randint(50, 200) for _ in range(3)],\n",
    "            'max_depth': [random.randint(1, 30) for _ in range(3)],\n",
    "            'min_samples_split': [random.randint(2, 10) for _ in range(3)],  # FIXED: Must be integer\n",
    "            'min_samples_leaf': [random.randint(1, 4) for _ in range(3)],  # FIXED: Avoid 0\n",
    "            'max_samples': [random.uniform(0.5, 1) for _ in range(3)],  # Adjusted range\n",
    "            'bootstrap': [True]  # Required for max_samples\n",
    "        }\n",
    "\n",
    "        # Randomized Search for efficiency\n",
    "        rf_model = RandomForestClassifier()\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=rf_model, \n",
    "            param_distributions=param_grid_rf, \n",
    "            scoring='accuracy', \n",
    "            cv=5, \n",
    "            n_iter=10,\n",
    "            n_jobs=-1,  # Randomly sample 10 hyperparameter combinations\n",
    "        )\n",
    "\n",
    "        # Fit the search\n",
    "        random_search.fit(X_train_train, y_train_train)\n",
    "\n",
    "        # Best hyperparameters\n",
    "        best_params = random_search.best_params_\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"] = best_params\n",
    "\n",
    "        # Best model evaluation\n",
    "        best_model = random_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        # Calculate sensitivity (true positive rate) and specificity (true negative rate)\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "        # Calculate ROC AUC score\n",
    "        auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store the metrics\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['auc'] = auc_score\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['f1'] = f1\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['sensitivity'] = sensitivity\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['specificity'] = specificity\n",
    "        best_params_list[f\"Outer {outer_rand} - Inner {inner_rand}\"]['accuracy'] = accuracy\n",
    "        print(f\"\\nOuter {outer_rand}, Inner {inner_rand} -> Best Hyperparameters: {best_params}\")\n",
    "        print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "    # Save file    \n",
    "    results_df = pd.DataFrame.from_dict(best_params_list, orient='index')\n",
    "    results_csv_path = os.path.join(os.getcwd(), 'best_hyperparameters.csv')\n",
    "    results_df.to_csv(results_csv_path)\n",
    "    print(f\"\\nBest parameters saved to {results_csv_path} after Outer {outer_rand}Â completion\")\n",
    "\n",
    "# Print all best parameters\n",
    "print(\"\\nBest Parameters Summary:\")\n",
    "for key, val in best_params_list.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
